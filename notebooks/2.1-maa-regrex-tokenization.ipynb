{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\coding\\text-proc-ml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\text-proc-ml\\.venv\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change.\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded.\n",
    "%autoreload 2\n",
    "\n",
    "# Смена рабочей папки.\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.3 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZE_RE = re.compile(r\"[а-яё]+|-?\\d*[.,]?\\d+|\\S\", re.I)\n",
    "# -?\\d*[.,]?\\d+\n",
    "\n",
    "\n",
    "def tokenize(txt):\n",
    "    return TOKENIZE_RE.findall(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тестовое сообщение\n",
      "мама мыла раму .\n",
      "контактный телефон : 123123 .\n",
      "что - нибудь надо придумать .\n",
      "значение числа е = 2.7182 .\n",
      "демон 123 , как тебя зовут в реале ?\n",
      "-1 -.15 = -1.15\n",
      "- 1 - .15 = -1.15\n",
      "какого ; % : ? * тут происходит ?\n"
     ]
    }
   ],
   "source": [
    "text_corpus = [\n",
    "    \"Тестовое сообщение\",\n",
    "    \"Мама мыла раму.\",\n",
    "    \"Контактный телефон: 123123.\",\n",
    "    \"Что-нибудь надо придумать.\",\n",
    "    \"Значение числа Е=2.7182.\",\n",
    "    \"Демон123, как тебя зовут в реале?\",\n",
    "    \"-1-.15=-1.15\",\n",
    "    \"- 1 - .15 = -1.15\",\n",
    "    \"Какого ;%:?* тут происходит?\",\n",
    "]\n",
    "for text_value in text_corpus:\n",
    "    print(\" \".join(tokenize(text_value.strip().lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4.5 Вектор весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dlnlputils.data import (\n",
    "    tokenize_text_simple_regex,\n",
    "    tokenize_corpus,\n",
    "    build_vocabulary,\n",
    "    vectorize_texts,\n",
    "    SparseFeaturesDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus_for_w = [\n",
    "    \"Казнить нельзя, помиловать. Нельзя наказывать.\",\n",
    "    \"Казнить, нельзя помиловать. Нельзя освободить.\",\n",
    "    \"Нельзя не помиловать.\",\n",
    "    \"Обязательно освободить.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokenized = tokenize_corpus(text_corpus_for_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['казнить', 'нельзя', 'помиловать', 'нельзя', 'наказывать'],\n",
       " ['казнить', 'нельзя', 'помиловать', 'нельзя', 'освободить'],\n",
       " ['нельзя', 'не', 'помиловать'],\n",
       " ['обязательно', 'освободить']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 7\n",
      "[('помиловать', 0), ('нельзя', 1), ('казнить', 2), ('освободить', 3), ('наказывать', 4), ('не', 5), ('обязательно', 6)]\n"
     ]
    }
   ],
   "source": [
    "MAX_DF = 1\n",
    "MIN_COUNT = 0\n",
    "vocabulary, word_doc_freq = build_vocabulary(\n",
    "    corpus_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT\n",
    ")\n",
    "UNIQUE_WORDS_N = len(vocabulary)\n",
    "print(\"Количество уникальных токенов\", UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = [(word, word_doc_freq[i]) for i, (word, _) in enumerate(vocabulary.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75, 0.75, 0.5 , 0.5 , 0.25, 0.25, 0.25], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "наказывать не обязательно казнить освободить нельзя помиловать\n",
      "0.25 0.25 0.25 0.5 0.5 0.75 0.75\n"
     ]
    }
   ],
   "source": [
    "answer = sorted(word_df, key=lambda x: (x[1], x[0]))\n",
    "\n",
    "\n",
    "answer_1 = []\n",
    "answer_2 = []\n",
    "\n",
    "for k, v in list(answer):\n",
    "    answer_1.append(k)\n",
    "    answer_2.append(str(v))\n",
    "\n",
    "print(\" \".join(answer_1))\n",
    "print(\" \".join(answer_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
